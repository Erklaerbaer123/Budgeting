{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eAYrDlGOsZPy",
        "0RZ74cMi-80J"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erklaerbaer123/Budgeting/blob/master/TransformerNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8PTVzuDsxyw"
      },
      "source": [
        "# TransformerNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6VYXFl0RgAx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "916QtgVv4OOE"
      },
      "source": [
        "import PIL as pil\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "#Import torch\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch import nn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiQ3HGc-OnL1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAYrDlGOsZPy"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj2pDHd7rHv0"
      },
      "source": [
        "# Tensorboard\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jBlYtlyrraF"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sba_VjEZr7q-"
      },
      "source": [
        "import os\n",
        "LOG_DIR = 'runs'\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxhdqiwEsqdc"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRyeNT07suUT"
      },
      "source": [
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fjN0pJ5vxux"
      },
      "source": [
        "writer = SummaryWriter(\"runs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg2KCL5nsfm-"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUViu6wwhnTw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RZ74cMi-80J"
      },
      "source": [
        "### Cifar Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "howun40zHv2i"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "     ])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3cRFfJy_C8q"
      },
      "source": [
        "### COCO Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq2iTzJGTnk7"
      },
      "source": [
        "from pycocotools.coco import COCO\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "coco = COCO(annotation_file=\"/content/drive/My Drive/Datasets/coco/annotations/instances_train2017.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH_Vn3yapra2"
      },
      "source": [
        "#cats = coco."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEQjUH2TmD2I"
      },
      "source": [
        "allIds = coco.getImgIds()\n",
        "\n",
        "len(allIds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgF9zniSmhIk"
      },
      "source": [
        "#catIds = coco.getCatIds(catNms=[\"zebra\"])\n",
        "annIds = coco.getAnnIds(imgIds=[144941])\n",
        "\n",
        "anns = coco.loadAnns(annIds)\n",
        "\n",
        "cat = coco.loadCats(anns[0][\"category_id\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIBhH4FsgnE8"
      },
      "source": [
        "img = coco.loadImgs(ids=144941)\n",
        "\n",
        "response = requests.get(img[0][\"coco_url\"])\n",
        "img = pil.Image.open(BytesIO(response.content))\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(img)\n",
        "#plt.show()\n",
        "\n",
        "coco.showAnns(anns, draw_bbox=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYOtzTYvlibI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfHaehPcLOPH"
      },
      "source": [
        "### Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nO56nnaGIiK"
      },
      "source": [
        "resnet50 = models.resnet50(pretrained=True, progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WApkx5KuFSrv"
      },
      "source": [
        "class transformer (nn.Module):\n",
        "  def __init__(self, hidden_dim):\n",
        "    super().__init__()\n",
        "    self.backbone = nn.Sequential(*list(resnet50.children())[:-2])\n",
        "    self.conv = nn.Conv2d(2048, 256, 1)\n",
        "    self.query_pos = nn.Parameter(torch.rand(100, hidden_dim))\n",
        "  def forward(self, inputs):\n",
        "    x = self.backbone(inputs)\n",
        "    h = self.conv(x)\n",
        "    print(h.size())\n",
        "    return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qRM7OIK4m-2"
      },
      "source": [
        "class DETR(nn.Module):\n",
        "  def __init__(self, num_classes, hidden_dim, nheads, num_encoder_layers, num_decoder_layers):\n",
        "    super().__init__() # We take only convolutional layers from ResNet-50 model\n",
        "    self.backbone = nn.Sequential(*list(resnet50.children())[:-2]) \n",
        "    self.conv = nn.Conv2d(2048, hidden_dim, 1)\n",
        "    self.transformer = nn.Transformer(hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
        "    self.linear_class = nn.Linear(hidden_dim, num_classes + 1)\n",
        "    self.linear_bbox = nn.Linear(hidden_dim, 4)\n",
        "    self.query_pos = nn.Parameter(torch.rand(100, hidden_dim))\n",
        "    self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
        "    self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    x = self.backbone(inputs)\n",
        "    print(x.size())\n",
        "    h = self.conv(x)\n",
        "    print(h.size())\n",
        "    H, W = h.shape[-2:]\n",
        "    print(\"h.flatten:\", h.flatten(2).permute(2, 0, 1).size())\n",
        "    print(\"H: \", H)\n",
        "    print(\"W: \", W)\n",
        "    col1 = self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1)\n",
        "    print(\"col_embed_normal:\", self.col_embed.size())\n",
        "    print(\"col_embed:\", self.col_embed[:W].size())\n",
        "    print(\"col1: \", col1.size())\n",
        "    print(\"col1_complete: \", self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1).size())\n",
        "    row1 = self.row_embed[:H].unsqueeze(1).repeat(1, W, 1)\n",
        "    pos = torch.cat([ col1, row1 , ], dim=-1).flatten(0, 1).unsqueeze(1)\n",
        "    h = self.transformer(pos + h.flatten(2).permute(2, 0, 1), self.query_pos.unsqueeze(1))\n",
        "    return self.linear_class(h), self.linear_bbox(h).sigmoid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DedS0ZZzHmtG"
      },
      "source": [
        "trans1 = transformer(hidden_dim=256)\n",
        "detr1 = DETR(10, 256, 1, 1 ,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iOTj_Qaq0j8"
      },
      "source": [
        "someImages  = [trainset[0][0], trainset[1][0]]\n",
        "\n",
        "writer.add_graph(trans1, trainset[0][0].unsqueeze(0))\n",
        "writer.close()\n",
        "#writer.add_graph(detr1, trainset[0][0].unsqueeze(0))\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJf13a325udM"
      },
      "source": [
        "trans1.eval()\n",
        "\n",
        "out = trans1(trainset[0][0].unsqueeze(0))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}